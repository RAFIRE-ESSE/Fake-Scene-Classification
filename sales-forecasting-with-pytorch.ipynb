{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":88742,"databundleVersionId":10173359},{"sourceType":"datasetVersion","sourceId":10011591,"datasetId":6148507,"databundleVersionId":10281208},{"sourceType":"datasetVersion","sourceId":9886329,"datasetId":6055019,"databundleVersionId":10141057}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mafiosoquasar/sales-forecasting-with-pytorch?scriptVersionId=209641694\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import argparse\nimport os\nimport random,numpy,pandas\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:53.127124Z","iopub.execute_input":"2024-11-25T15:53:53.127449Z","iopub.status.idle":"2024-11-25T15:53:53.131877Z","shell.execute_reply.started":"2024-11-25T15:53:53.127418Z","shell.execute_reply":"2024-11-25T15:53:53.130918Z"}},"outputs":[],"execution_count":274},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport torchvision.transforms.functional as RF\nfrom PIL import Image\nimport numpy as np\nimport random,cv2,pandas,os,numpy\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:53.149393Z","iopub.execute_input":"2024-11-25T15:53:53.149653Z","iopub.status.idle":"2024-11-25T15:53:53.154737Z","shell.execute_reply.started":"2024-11-25T15:53:53.149627Z","shell.execute_reply":"2024-11-25T15:53:53.153842Z"}},"outputs":[],"execution_count":275},{"cell_type":"code","source":"seed = 999\nprint(\"Random Seed: \", seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True)\n\nnz = 100\nbeta1 = 0.5\nlr = 0.01\nbatch_size=100\nngpu=1\nngf,nc = 3,3\nndf = 64\n\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:53.170945Z","iopub.execute_input":"2024-11-25T15:53:53.171179Z","iopub.status.idle":"2024-11-25T15:53:53.177909Z","shell.execute_reply.started":"2024-11-25T15:53:53.171156Z","shell.execute_reply":"2024-11-25T15:53:53.177056Z"}},"outputs":[{"name":"stdout","text":"Random Seed:  999\n","output_type":"stream"}],"execution_count":276},{"cell_type":"code","source":"x = pandas.read_csv(\"/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv\").sort_values(by=['date', 'warehouse'])\n\nx = torch.from_numpy(numpy.nan_to_num(x[['total_orders', 'sell_price_main', 'type_0_discount', 'type_1_discount',\n                                         'type_2_discount', 'type_3_discount', 'type_4_discount',  'type_5_discount', \n                                         'type_6_discount']].to_numpy().astype(numpy.float32)).reshape((13, 308263, 9)))\nx.shape #4315682\n\nclass EC_NET(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.rafire = nn.Sequential(       \n            nn.Linear(9, 1524),\n            nn.Linear(1524, 824),\n            nn.Linear(824, 424),\n            nn.Linear(424, 124),\n            nn.Linear(124, 100)\n        )\n\n    def forward(self,x):\n        \n        return self.rafire(x)\nec_net = EC_NET().type(torch.float32).to(device).eval()\nec_net= nn.DataParallel(ec_net).to(device)\nrf_net.load_state_dict(torch.load(\"/kaggle/input/encoder-weight-data/weight.pth\",weights_only=False,map_location=torch.device('cpu')))\n\nj=0\nfor i in x:\n    print(f\"loding batch : {j}\")\n    if j==0:\n        encode = ec_net(i).cpu().detach().numpy().reshape((len(i),10,10))\n        print(encode.shape)\n    else:\n        encode = numpy.concatenate((encode, ec_net(i).cpu().detach().numpy().reshape((len(i),10,10))), axis=0)\n    #if j==25:\n    #    break\n    j+=1\n\nx=torch.Tensor(encode)[::100]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y=pandas.read_csv(\"/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv\").sort_values(by=['date', 'warehouse'])\ny=torch.from_numpy(numpy.nan_to_num(y['sales'].to_numpy().astype(numpy.float32))).reshape(len(y),1)[::100]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:53.210963Z","iopub.execute_input":"2024-11-25T15:53:53.211205Z","iopub.status.idle":"2024-11-25T15:53:58.85439Z","shell.execute_reply.started":"2024-11-25T15:53:53.211181Z","shell.execute_reply":"2024-11-25T15:53:58.853696Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/566033409.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  x = torch.load(\"/kaggle/input/encoder-weight-data/train_tensor.pt\")[::100]\n","output_type":"stream"}],"execution_count":277},{"cell_type":"code","source":"x.shape, y.shape, x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:58.856119Z","iopub.execute_input":"2024-11-25T15:53:58.856788Z","iopub.status.idle":"2024-11-25T15:53:58.863698Z","shell.execute_reply.started":"2024-11-25T15:53:58.856743Z","shell.execute_reply":"2024-11-25T15:53:58.862872Z"}},"outputs":[{"execution_count":278,"output_type":"execute_result","data":{"text/plain":"(torch.Size([40075, 1]),\n torch.Size([40075, 1]),\n tensor([[25.9468],\n         [25.3594],\n         [26.0216],\n         ...,\n         [27.3667],\n         [29.2135],\n         [30.7281]]))"},"metadata":{}}],"execution_count":278},{"cell_type":"code","source":"train_x = torch.utils.data.DataLoader(x,batch_size=batch_size)\ntrain_y = torch.utils.data.DataLoader(y,batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:58.8648Z","iopub.execute_input":"2024-11-25T15:53:58.865038Z","iopub.status.idle":"2024-11-25T15:53:58.871502Z","shell.execute_reply.started":"2024-11-25T15:53:58.865013Z","shell.execute_reply":"2024-11-25T15:53:58.870791Z"}},"outputs":[],"execution_count":279},{"cell_type":"code","source":"def weights_init(m):\n    if isinstance(m, nn.Linear):\n        nn.init.xavier_normal_(m.weight.data, gain=0.02)\n        \nclass RF_NET(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.rafire_1 = nn.LSTMCell(1, 1524)\n                                     #nn.BatchNorm1d(1524),\n                                     #nn.ReLU())\n\n        self.rafire_2 = nn.LSTMCell(1524, 1324)\n                                     #nn.BatchNorm1d(1324),\n                                     #nn.LeakyReLU())\n\n        self.rafire_3 = nn.LSTMCell(1324, 1024)\n                                     #nn.BatchNorm1d(1024),\n                                     #nn.LeakyReLU())\n\n        self.rafire_4 = nn.LSTMCell(1024, 824)\n                                     #nn.BatchNorm1d(824),\n                                     #nn.LeakyReLU())\n\n        self.rafire_5 = nn.LSTMCell(824, 524)\n                                     #nn.BatchNorm1d(524),\n                                     #nn.LeakyReLU())\n\n        self.rafire_6 = nn.LSTMCell(524, 324)\n                                     #nn.BatchNorm1d(324),\n                                     #nn.LeakyReLU())\n\n        self.rafire_7 = nn.LSTMCell(324, 124)\n                                    #nn.BatchNorm1d(124),\n                                    #nn.LeakyReLU())\n            \n        self.rafire_8 = nn.Linear(124, 1)\n\n    def forward(self,x):\n        x,_=self.rafire_1(x)\n        x,_=self.rafire_2(x)\n        x,_=self.rafire_3(x)\n        x,_=self.rafire_4(x)\n        x,_=self.rafire_5(x)\n        x,_=self.rafire_6(x)\n        x,_=self.rafire_7(x)\n        \n        return self.rafire_8(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:58.87355Z","iopub.execute_input":"2024-11-25T15:53:58.873874Z","iopub.status.idle":"2024-11-25T15:53:58.881368Z","shell.execute_reply.started":"2024-11-25T15:53:58.873837Z","shell.execute_reply":"2024-11-25T15:53:58.880563Z"}},"outputs":[],"execution_count":280},{"cell_type":"code","source":"rf_net = RF_NET().type(torch.float32).to(device)\nrf_net= nn.DataParallel(rf_net).to(device)\nif (device.type == 'cuda') and (ngpu > 1):\n    rf_net = nn.DataParallel(rf_net, list(range(ngpu)))\nrf_net.apply(weights_init)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:58.8824Z","iopub.execute_input":"2024-11-25T15:53:58.882654Z","iopub.status.idle":"2024-11-25T15:53:59.268478Z","shell.execute_reply.started":"2024-11-25T15:53:58.88263Z","shell.execute_reply":"2024-11-25T15:53:59.267597Z"}},"outputs":[{"execution_count":281,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): RF_NET(\n    (rafire_1): LSTMCell(1, 1524)\n    (rafire_2): LSTMCell(1524, 1324)\n    (rafire_3): LSTMCell(1324, 1024)\n    (rafire_4): LSTMCell(1024, 824)\n    (rafire_5): LSTMCell(824, 524)\n    (rafire_6): LSTMCell(524, 324)\n    (rafire_7): LSTMCell(324, 124)\n    (rafire_8): Linear(in_features=124, out_features=1, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":281},{"cell_type":"code","source":"criterion = nn.L1Loss()\n\noptimizer = optim.AdamW(rf_net.parameters(), lr=lr,betas=(beta1, 0.999))\nscheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.86)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:59.2697Z","iopub.execute_input":"2024-11-25T15:53:59.270018Z","iopub.status.idle":"2024-11-25T15:53:59.277585Z","shell.execute_reply.started":"2024-11-25T15:53:59.269989Z","shell.execute_reply":"2024-11-25T15:53:59.276743Z"}},"outputs":[],"execution_count":282},{"cell_type":"code","source":"high_rf,i,j_r,k,z_w_=100000,0,0,0,[]\nif os.path.exists(f\"/kaggle/working/jsr_rf\")==False:\n    os.mkdir(f\"/kaggle/working/jsr_rf\")\n    \ncorrect,total=0,0\n\nwhile(True):\n    optimizer.zero_grad()\n    for data,label in zip(train_x,train_y):\n        #z_ = nn.Embedding(10, 3, dtype=torch.float64)\n        #print(z_(torch.FloatTensor(data)))\n        \n        output = rf_net(data.to(device)).view(-1)\n        err_real = criterion(output, label.to(device))\n        err_real.backward()\n        optimizer.step()\n        #print(err_real.item())\n        \n    print(f\"EPOCH : {i} LOSS_wl : {err_real.item()}\")\n\n    if len(z_w_)>=3:\n        if len([True for i in range(1,4) if z_w_[len(z_w_)-i]<=z_w_[len(z_w_)-3] and z_w_[len(z_w_)-i]>=z_w_[len(z_w_)-4]])==3:\n            z_w_,j_r=[],0\n            print(f\"lr_br:{optimizer.param_groups[0]['lr']}\".upper())\n            scheduler.step()\n            print(f\"lr_up:{optimizer.param_groups[0]['lr']}\".upper())\n            \n    z_w_.append(err_real.item())\n    if err_real.item()<high_rf:\n            high_rf=err_real.item()\n            torch.save(rf_net.state_dict(),f'/kaggle/working/jsr_rf/{err_real.item()}.pth')\n    if i==100:\n        break\n    i+=1","metadata":{"_kg_hide-input":false,"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T15:53:59.278488Z","iopub.execute_input":"2024-11-25T15:53:59.278782Z","iopub.status.idle":"2024-11-25T16:32:27.673708Z","shell.execute_reply.started":"2024-11-25T15:53:59.278757Z","shell.execute_reply":"2024-11-25T16:32:27.672788Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([100, 1])) that is different to the input size (torch.Size([100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.l1_loss(input, target, reduction=self.reduction)\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([75, 1])) that is different to the input size (torch.Size([75])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.l1_loss(input, target, reduction=self.reduction)\n","output_type":"stream"},{"name":"stdout","text":"EPOCH : 0 LOSS_wl : 111.59806060791016\nEPOCH : 1 LOSS_wl : 117.55054473876953\nEPOCH : 2 LOSS_wl : 110.01910400390625\nEPOCH : 3 LOSS_wl : 110.89949035644531\nEPOCH : 4 LOSS_wl : 111.52262115478516\nEPOCH : 5 LOSS_wl : 110.16775512695312\nEPOCH : 6 LOSS_wl : 111.755615234375\nEPOCH : 7 LOSS_wl : 110.42478942871094\nEPOCH : 8 LOSS_wl : 111.56241607666016\nEPOCH : 9 LOSS_wl : 110.26602172851562\nLR_BR:0.01\nLR_UP:0.0086\nEPOCH : 10 LOSS_wl : 108.74249267578125\nEPOCH : 11 LOSS_wl : 107.75145721435547\nEPOCH : 12 LOSS_wl : 109.53330993652344\nLR_BR:0.0086\nLR_UP:0.007396\nEPOCH : 13 LOSS_wl : 111.6804428100586\nEPOCH : 14 LOSS_wl : 107.55406951904297\nEPOCH : 15 LOSS_wl : 108.58694458007812\nEPOCH : 16 LOSS_wl : 111.00308990478516\nEPOCH : 17 LOSS_wl : 107.83633422851562\nEPOCH : 18 LOSS_wl : 108.67230224609375\nEPOCH : 19 LOSS_wl : 109.56366729736328\nEPOCH : 20 LOSS_wl : 108.15509033203125\nEPOCH : 21 LOSS_wl : 108.86256408691406\nEPOCH : 22 LOSS_wl : 108.7469482421875\nEPOCH : 23 LOSS_wl : 108.5175552368164\nEPOCH : 24 LOSS_wl : 108.69285583496094\nLR_BR:0.007396\nLR_UP:0.0063605599999999995\nEPOCH : 25 LOSS_wl : 109.12248992919922\nEPOCH : 26 LOSS_wl : 107.6153564453125\nEPOCH : 27 LOSS_wl : 109.2574234008789\nEPOCH : 28 LOSS_wl : 111.77332305908203\nEPOCH : 29 LOSS_wl : 109.3096694946289\nEPOCH : 30 LOSS_wl : 107.58720397949219\nEPOCH : 31 LOSS_wl : 109.18024444580078\nEPOCH : 32 LOSS_wl : 112.02388763427734\nEPOCH : 33 LOSS_wl : 109.08555603027344\nEPOCH : 34 LOSS_wl : 107.62491607666016\nEPOCH : 35 LOSS_wl : 109.26896667480469\nEPOCH : 36 LOSS_wl : 111.58621215820312\nEPOCH : 37 LOSS_wl : 109.0447998046875\nEPOCH : 38 LOSS_wl : 107.63130950927734\nEPOCH : 39 LOSS_wl : 109.3356704711914\nEPOCH : 40 LOSS_wl : 111.24931335449219\nEPOCH : 41 LOSS_wl : 108.63768768310547\nEPOCH : 42 LOSS_wl : 107.70885467529297\nEPOCH : 43 LOSS_wl : 109.8289794921875\nEPOCH : 44 LOSS_wl : 109.39557647705078\nEPOCH : 45 LOSS_wl : 107.66539764404297\nEPOCH : 46 LOSS_wl : 107.9107894897461\nEPOCH : 47 LOSS_wl : 110.11518859863281\nEPOCH : 48 LOSS_wl : 107.93988800048828\nEPOCH : 49 LOSS_wl : 107.89701080322266\nEPOCH : 50 LOSS_wl : 108.30366516113281\nEPOCH : 51 LOSS_wl : 108.3816909790039\nEPOCH : 52 LOSS_wl : 107.89876556396484\nEPOCH : 53 LOSS_wl : 108.14004516601562\nEPOCH : 54 LOSS_wl : 108.53816986083984\nEPOCH : 55 LOSS_wl : 107.8572006225586\nEPOCH : 56 LOSS_wl : 108.150390625\nEPOCH : 57 LOSS_wl : 108.54788970947266\nEPOCH : 58 LOSS_wl : 107.8626480102539\nEPOCH : 59 LOSS_wl : 108.15738677978516\nEPOCH : 60 LOSS_wl : 108.55073547363281\nEPOCH : 61 LOSS_wl : 107.84071350097656\nEPOCH : 62 LOSS_wl : 108.17257690429688\nEPOCH : 63 LOSS_wl : 108.5997543334961\nEPOCH : 64 LOSS_wl : 107.80648803710938\nEPOCH : 65 LOSS_wl : 108.21904754638672\nEPOCH : 66 LOSS_wl : 108.52178955078125\nEPOCH : 67 LOSS_wl : 107.86032104492188\nEPOCH : 68 LOSS_wl : 108.112060546875\nEPOCH : 69 LOSS_wl : 108.59113311767578\nEPOCH : 70 LOSS_wl : 107.85430145263672\nEPOCH : 71 LOSS_wl : 108.11917114257812\nEPOCH : 72 LOSS_wl : 108.57562255859375\nEPOCH : 73 LOSS_wl : 107.8452377319336\nEPOCH : 74 LOSS_wl : 108.16108703613281\nEPOCH : 75 LOSS_wl : 108.57176971435547\nEPOCH : 76 LOSS_wl : 107.84090423583984\nEPOCH : 77 LOSS_wl : 108.17965698242188\nEPOCH : 78 LOSS_wl : 108.5542221069336\nEPOCH : 79 LOSS_wl : 107.84410858154297\nEPOCH : 80 LOSS_wl : 108.15664672851562\nEPOCH : 81 LOSS_wl : 108.57113647460938\nEPOCH : 82 LOSS_wl : 107.83177947998047\nEPOCH : 83 LOSS_wl : 108.18206024169922\nEPOCH : 84 LOSS_wl : 108.57611083984375\nEPOCH : 85 LOSS_wl : 107.8299560546875\nEPOCH : 86 LOSS_wl : 108.17176818847656\nEPOCH : 87 LOSS_wl : 108.59713745117188\nEPOCH : 88 LOSS_wl : 107.83329010009766\nEPOCH : 89 LOSS_wl : 108.16854858398438\nEPOCH : 90 LOSS_wl : 108.60416412353516\nEPOCH : 91 LOSS_wl : 107.80341339111328\nEPOCH : 92 LOSS_wl : 108.21434783935547\nEPOCH : 93 LOSS_wl : 108.54403686523438\nEPOCH : 94 LOSS_wl : 107.84066009521484\nEPOCH : 95 LOSS_wl : 108.1761474609375\nEPOCH : 96 LOSS_wl : 108.57553100585938\nEPOCH : 97 LOSS_wl : 107.83097839355469\nEPOCH : 98 LOSS_wl : 108.16699981689453\nEPOCH : 99 LOSS_wl : 108.5726089477539\nEPOCH : 100 LOSS_wl : 107.83025360107422\n","output_type":"stream"}],"execution_count":283}]}