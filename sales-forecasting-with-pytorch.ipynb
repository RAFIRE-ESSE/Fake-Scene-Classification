{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":88742,"databundleVersionId":10173359,"sourceType":"competition"},{"sourceId":9886329,"sourceType":"datasetVersion","datasetId":6055019},{"sourceId":10011591,"sourceType":"datasetVersion","datasetId":6148507}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mafiosoquasar/time-series-sales-forecasting-with-pytorch?scriptVersionId=211033466\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import argparse\nimport os\nimport random,numpy\nos.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pandas ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.utils.data\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport torchvision.transforms.functional as RF\nfrom torchvision.models.feature_extraction import create_feature_extractor\nfrom PIL import Image\nimport numpy as np\nimport random,cv2,pandas,os,numpy\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 999\nprint(\"Random Seed: \", seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.use_deterministic_algorithms(True)\n\nnz = 100\nbeta1 = 0.5\nlr = 0.0001\nbatch_size=1000\nngpu=1\nngf,nc = 3,3\nndf = 64\nshape=(308263,10)\n\ndevice = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pandas.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv', parse_dates=['date'])\ntest = pandas.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_test.csv', parse_dates=['date'])\nss = pandas.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/solution.csv')\n\ninventory = pandas.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/inventory.csv')\nweights = pandas.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/test_weights.csv')\ncalendar = pandas.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/calendar.csv', parse_dates=['date'])\n\nFrankfurt_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Frankfurt_1\"')\nPrague_2 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_2\"')\nBrno_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Brno_1\"')\nMunich_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Munich_1\"')\nPrague_3 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_3\"')\nPrague_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Prague_1\"')\nBudapest_1 = calendar.query('date >= \"2020-08-01 00:00:00\" and warehouse ==\"Budapest_1\"')\n\ndef process_calendar(df):\n\n    df = df.sort_values('date').reset_index(drop=True)\n\n    df['next_holiday_date'] = df.loc[df['holiday'] == 1, 'date'].shift(-1)\n    df['next_holiday_date'] = df['next_holiday_date'].bfill()\n    df['days_to_holiday'] = (df['next_holiday_date'] - df['date']).dt.days\n    df.drop(columns=['next_holiday_date'], inplace=True)\n\n    df['next_shops_closed_date'] = df.loc[df['shops_closed'] == 1, 'date'].shift(-1)\n    df['next_shops_closed_date'] = df['next_shops_closed_date'].bfill()\n    df['days_to_shops_closed'] = (df['next_shops_closed_date'] - df['date']).dt.days\n    df.drop(columns=['next_shops_closed_date'], inplace=True)\n\n    df['day_after_closing'] = (\n        (df['shops_closed'] == 0) & (df['shops_closed'].shift(1) == 1)\n    ).astype(int)\n\n    df['long_weekend'] = (\n        (df['shops_closed'] == 1) & (df['shops_closed'].shift(1) == 1)\n    ).astype(int)\n\n    df['weekday'] = df['date'].dt.weekday \n    return df\n\ndfs = ['Frankfurt_1', 'Prague_2', 'Brno_1', 'Munich_1', 'Prague_3', 'Prague_1', 'Budapest_1']\n\nprocessed_dfs = [process_calendar(globals()[df]) for df in dfs]\n\ncalendar_extended = pandas.concat(processed_dfs).sort_values('date').reset_index(drop=True)\n\ntrain_calendar = train.merge(calendar_extended, on=['date', 'warehouse'], how='left')\ntrain_inventory = train_calendar.merge(inventory, on=['unique_id', 'warehouse'], how='left')\ntrain_data = train_inventory.merge(weights, on=['unique_id'], how='left')\n\ntest_calendar = test.merge(calendar_extended, on=['date', 'warehouse'], how='left')\n\ntest_data = test_calendar.merge(inventory, on=['unique_id', 'warehouse'], how='left')\n\ntrain_data.dropna(subset=['sales'], inplace=True)\ntrain_data = train_data.sort_values(['unique_id', 'date'])\n\ntrain_data.head()\n\ntrain_data_ = train_data.drop(columns=['availability'])\ntrain_data_ = train_data_.drop(columns=['weight'])\nx = train_data_.drop(columns=['sales'])\n\nx.columns, test_data.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = x['unique_id', 'date', 'warehouse', 'total_orders', 'sell_price_main',\n        'type_0_discount', 'type_1_discount', 'type_2_discount',\n        'type_3_discount', 'type_4_discount', 'type_5_discount',\n        'type_6_discount']\ntest_data = test_data['unique_id', 'date', 'warehouse', 'total_orders', 'sell_price_main',\n        'type_0_discount', 'type_1_discount', 'type_2_discount',\n        'type_3_discount', 'type_4_discount', 'type_5_discount',\n        'type_6_discount']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_columns = x.select_dtypes(include=['object']).columns.tolist()\nencoder = OneHotEncoder(sparse_output=False)\none_hot_encoded = encoder.fit_transform(x[categorical_columns])\n\ncategorical_columns_ = test_data.select_dtypes(include=['object']).columns.tolist()\nsub_ = encoder.fit_transform(test_data[categorical_columns_])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = torch.from_numpy(one_hot_encoded).type('torch.FloatTensor')\ny = torch.from_numpy(train_data_['sales'].to_numpy()).type('torch.FloatTensor')\nsub = torch.from_numpy(sub_).type('torch.FloatTensor')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x.shape, y.shape, x.shape, sub.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_x = torch.utils.data.DataLoader(x,batch_size=batch_size)\ntrain_y = torch.utils.data.DataLoader(y,batch_size=batch_size)\ntest_sub = torch.utils.data.DataLoader(sub,batch_size=batch_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def weights_init(m):\n    if isinstance(m, nn.Linear):\n        nn.init.xavier_normal_(m.weight.data, gain=0.02)\n        \nclass RF_NET(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.rafire = nn.Sequential(\n            \n            nn.Linear(2991, 1524),\n            nn.BatchNorm1d(1524),\n            nn.ReLU(),\n            \n            nn.Linear(1524, 824),\n            nn.BatchNorm1d(824),\n            nn.ReLU(),\n            \n            nn.Linear(824, 424),\n            nn.BatchNorm1d(424),\n            nn.ReLU(),\n            \n            nn.Linear(424, 212),\n            nn.BatchNorm1d(212),\n            nn.ReLU(),\n            \n            nn.Linear(212, 124),\n            nn.BatchNorm1d(124),\n            nn.ReLU(),\n            \n            nn.Linear(124, 1)\n        )\n\n    def forward(self,x):\n        #x,_=self.rafire_0(x)\n        #print(x,x.shape)\n        return self.rafire(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EFF_NET = RF_NET().float()\nEFF_NET= nn.DataParallel(EFF_NET).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.L1Loss()\n\noptimizer = optim.AdamW(EFF_NET.parameters(), lr=lr,betas=(beta1, 0.999))\nscheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.86)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"high_rf,i,j_r,k,z_w_=100000,0,0,0,[]\n    \ncorrect,total=0,0\n\nwhile(True):\n    optimizer.zero_grad()\n    for data,label in zip(train_x,train_y):\n        #z_ = nn.Embedding(10, 3, dtype=torch.float64)\n        #print(z_(torch.FloatTensor(data)))\n        output = EFF_NET(data.to(device)).view(-1)\n        err_real = criterion(output, label.to(device))\n        err_real.backward()\n        optimizer.step()\n        #print(err_real.item())\n        \n    print(f\"EPOCH : {i} LOSS_wl : {err_real.item()}\")\n\n    if len(z_w_)>=3:\n        if len([True for i in range(1,4) if z_w_[len(z_w_)-i]<=z_w_[len(z_w_)-3] and z_w_[len(z_w_)-i]>=z_w_[len(z_w_)-4]])==3:\n            z_w_,j_r=[],0\n            print(f\"lr_br:{optimizer.param_groups[0]['lr']}\".upper())\n            scheduler.step()\n            print(f\"lr_up:{optimizer.param_groups[0]['lr']}\".upper())\n            \n    z_w_.append(err_real.item())\n    if err_real.item()<high_rf:\n            high_rf=err_real.item()\n            torch.save(EFF_NET.state_dict(),f'/kaggle/working/{err_real.item()}.pth')\n    if i==3:\n        break\n    i+=1","metadata":{"_kg_hide-input":false,"trusted":true},"outputs":[],"execution_count":null}]}